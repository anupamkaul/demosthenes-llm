Noting an error when running inference.py on google colab
(on a tesla GPU) : I was able to train the model and save the model file

/home/anupam/demosthenes-llm/finetune-classification# python inference.py
model loaded in 0.04 minutes.
[50256]
120
120
120
Input batch dimensions: torch.Size([8, 120])
Label batch dimensions torch.Size([8])
130 training batches
19 validation batches
38 test batches

Check for Spam:  You are a winner you have been specially selected to receive $1000 cash or a $2000 award.
Traceback (most recent call last):
  File "/home/anupam/demosthenes-llm/finetune-classification/inference.py", line 94, in <module>
    print(classify_review(
          ^^^^^^^^^^^^^^^^
  File "/home/anupam/demosthenes-llm/finetune-classification/inference.py", line 76, in classify_review
    logits = model(input_tensor)[:, -1, :]    # logits of the last output token
             ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/anupam/demosthenes-llm/finetune-classification/../llm-infra/GPTModel.py", line 50, in forward
    tok_embeds = self.tok_emb(in_idx)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/sparse.py", line 192, in forward
    return F.embedding(
           ^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py", line 2542, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but got index is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA__index_select)
/home/anupam/demosthenes-llm/finetune-classification# 
