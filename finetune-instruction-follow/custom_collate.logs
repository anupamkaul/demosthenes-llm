# showing that if batch sizes are different, using custom_collate_draft1,
# paddings are applied to normalize but the padding lengths are a function 
# of the individual batch sizes, not the entire dataset, which can help to
# optimize space and time for compute:

python test_custom_collate.py
Len of data:  1100
Training set length: 935
Test set length: 110
Validation set length: 55
[50256]
custom collate draft 1 (batch-1):
 tensor([[    0,     1,     2,     3,     4],
        [    5,     6, 50256, 50256, 50256],
        [    7,     8,     9, 50256, 50256]])
custom collate draft 1 (batch-2):
 tensor([[    1,     2,     3,     4,     5,     6,     7,     7,    98,    99,
           102,   103,   999],
        [    1,     3, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,
         50256, 50256, 50256],
        [    0,     1,     2,     3,     4,     5,     6, 50256, 50256, 50256,
         50256, 50256, 50256]])

