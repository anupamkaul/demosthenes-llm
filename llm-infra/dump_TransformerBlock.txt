current dir:  /Users/anupkaul/akaul_git/demosthenes-llm/llm-infra 

addnl module path to be used for import:  /Users/anupkaul/akaul_git/demosthenes-llm/llm-infra/../attention/ 

causal masked bool tensor:
 tensor([[False,  True,  True,  True],
        [False, False,  True,  True],
        [False, False, False,  True],
        [False, False, False, False]])
attn scores masked causal:
 tensor([[[[ 0.9755,    -inf,    -inf,    -inf],
          [ 0.5178, -3.1479,    -inf,    -inf],
          [ 2.1150, -1.8031, -0.1007,    -inf],
          [-5.5577,  0.3575, -1.6647,  0.3256]],

         [[-5.3523,    -inf,    -inf,    -inf],
          [ 7.2249, -3.2465,    -inf,    -inf],
          [ 6.0894,  0.9030,  0.3381,    -inf],
          [-1.8323,  1.0956,  3.2083, -1.4368]],

         [[-0.7987,    -inf,    -inf,    -inf],
          [-1.9262, -0.1537,    -inf,    -inf],
          [ 1.6670, -1.5751, -4.0864,    -inf],
          [-1.7564, -0.0709, -1.4566, -3.3338]],

         [[-1.8932,    -inf,    -inf,    -inf],
          [-3.4902, -0.1443,    -inf,    -inf],
          [ 2.5352,  5.3311,  2.1643,    -inf],
          [ 0.4084, -2.8870,  1.6750,  1.2255]],

         [[-1.5869,    -inf,    -inf,    -inf],
          [-1.3316, -3.4588,    -inf,    -inf],
          [ 4.3212,  2.2483,  0.3847,    -inf],
          [-0.0928,  2.8840, -0.2084,  3.1476]],

         [[-2.4964,    -inf,    -inf,    -inf],
          [ 0.5827, -4.9596,    -inf,    -inf],
          [ 0.7521, -3.2974, -1.2414,    -inf],
          [-3.9935, -2.7641,  2.1798,  2.7842]],

         [[-0.4399,    -inf,    -inf,    -inf],
          [-5.3584, -3.6256,    -inf,    -inf],
          [ 0.1444,  2.7679,  1.5975,    -inf],
          [ 1.3976,  0.5703, -4.4828, -2.9024]],

         [[ 0.7689,    -inf,    -inf,    -inf],
          [-0.7867,  0.8788,    -inf,    -inf],
          [-1.2045, -0.6461,  0.1792,    -inf],
          [ 1.5992,  1.2974,  2.6095,  1.5178]],

         [[-0.9417,    -inf,    -inf,    -inf],
          [ 5.3988, -0.4846,    -inf,    -inf],
          [-2.0497,  1.2294,  3.0581,    -inf],
          [ 2.4859, -1.3673, -1.2563, -0.8478]],

         [[ 2.8521,    -inf,    -inf,    -inf],
          [ 5.5531,  1.4236,    -inf,    -inf],
          [ 0.9316,  0.0852,  1.4256,    -inf],
          [-1.5060,  1.4610,  0.9809, -1.7037]],

         [[-1.4494,    -inf,    -inf,    -inf],
          [ 0.9759,  2.3361,    -inf,    -inf],
          [ 1.1474, -2.6141,  1.8370,    -inf],
          [ 1.1620,  0.0192,  1.5117, -4.8726]],

         [[-0.1563,    -inf,    -inf,    -inf],
          [-0.9255,  2.2866,    -inf,    -inf],
          [ 0.4373,  2.4027, -0.2230,    -inf],
          [ 1.9590, -1.6532, -0.2924,  0.6398]]],


        [[[-2.7538,    -inf,    -inf,    -inf],
          [-6.5033,  0.9874,    -inf,    -inf],
          [ 2.5690, -1.7029, -1.6760,    -inf],
          [ 3.4883, -4.6489,  0.1307,  4.3630]],

         [[-0.3881,    -inf,    -inf,    -inf],
          [ 0.7194,  2.5607,    -inf,    -inf],
          [-1.0136,  2.6440,  2.3192,    -inf],
          [ 1.5569, -2.0869, -1.8644, -1.5261]],

         [[ 5.3692,    -inf,    -inf,    -inf],
          [ 1.1280,  1.1004,    -inf,    -inf],
          [ 3.2275, -2.1077,  2.9624,    -inf],
          [-1.2452,  0.5275,  0.2657, -3.3152]],

         [[-3.2958,    -inf,    -inf,    -inf],
          [ 2.7911, -2.0027,    -inf,    -inf],
          [-2.0515, -0.0987, -5.6008,    -inf],
          [-3.3904, -0.8602, -1.3953,  4.1308]],

         [[ 4.9805,    -inf,    -inf,    -inf],
          [ 1.6964,  2.1793,    -inf,    -inf],
          [ 0.2616,  0.9180,  1.7163,    -inf],
          [-1.5686,  3.4390,  3.6824,  1.4223]],

         [[ 2.4012,    -inf,    -inf,    -inf],
          [ 0.3229, -2.3132,    -inf,    -inf],
          [ 3.3178, -0.8648, -1.3131,    -inf],
          [-1.3808,  1.4659,  3.1666,  4.2573]],

         [[-2.5406,    -inf,    -inf,    -inf],
          [-0.7288,  2.0287,    -inf,    -inf],
          [ 0.6834, -4.3049,  2.0619,    -inf],
          [-0.6421, -2.8358, -0.7856,  2.2456]],

         [[ 1.1350,    -inf,    -inf,    -inf],
          [ 2.4337,  5.9735,    -inf,    -inf],
          [ 2.2667, -2.1464,  0.7315,    -inf],
          [-0.0347,  1.0978,  0.6024,  0.4553]],

         [[ 1.5933,    -inf,    -inf,    -inf],
          [-0.7608, -1.6384,    -inf,    -inf],
          [ 3.3346, -0.2370,  0.2977,    -inf],
          [-2.8944,  2.7261, -2.7417, -5.4433]],

         [[ 1.6374,    -inf,    -inf,    -inf],
          [ 0.0825,  0.3075,    -inf,    -inf],
          [ 3.0984,  1.7380, -1.1743,    -inf],
          [ 0.9610, -3.3473, -0.5385, -1.0962]],

         [[ 2.9763,    -inf,    -inf,    -inf],
          [-6.4965, -0.2624,    -inf,    -inf],
          [-0.8513, -1.5362,  3.4230,    -inf],
          [-0.9650,  0.8047, -0.3094, -6.6811]],

         [[-2.5711,    -inf,    -inf,    -inf],
          [-0.3285,  0.3242,    -inf,    -inf],
          [-3.2146, -0.2453, -0.2311,    -inf],
          [ 0.9251, -1.4006, -2.7559, -0.0601]]]],
       grad_fn=<MaskedFillBackward0>)
attn weights tensor:
 tensor([[[[ 0.9755,    -inf,    -inf,    -inf],
          [ 0.5178, -3.1479,    -inf,    -inf],
          [ 2.1150, -1.8031, -0.1007,    -inf],
          [-5.5577,  0.3575, -1.6647,  0.3256]],

         [[-5.3523,    -inf,    -inf,    -inf],
          [ 7.2249, -3.2465,    -inf,    -inf],
          [ 6.0894,  0.9030,  0.3381,    -inf],
          [-1.8323,  1.0956,  3.2083, -1.4368]],

         [[-0.7987,    -inf,    -inf,    -inf],
          [-1.9262, -0.1537,    -inf,    -inf],
          [ 1.6670, -1.5751, -4.0864,    -inf],
          [-1.7564, -0.0709, -1.4566, -3.3338]],

         [[-1.8932,    -inf,    -inf,    -inf],
          [-3.4902, -0.1443,    -inf,    -inf],
          [ 2.5352,  5.3311,  2.1643,    -inf],
          [ 0.4084, -2.8870,  1.6750,  1.2255]],

         [[-1.5869,    -inf,    -inf,    -inf],
          [-1.3316, -3.4588,    -inf,    -inf],
          [ 4.3212,  2.2483,  0.3847,    -inf],
          [-0.0928,  2.8840, -0.2084,  3.1476]],

         [[-2.4964,    -inf,    -inf,    -inf],
          [ 0.5827, -4.9596,    -inf,    -inf],
          [ 0.7521, -3.2974, -1.2414,    -inf],
          [-3.9935, -2.7641,  2.1798,  2.7842]],

         [[-0.4399,    -inf,    -inf,    -inf],
          [-5.3584, -3.6256,    -inf,    -inf],
          [ 0.1444,  2.7679,  1.5975,    -inf],
          [ 1.3976,  0.5703, -4.4828, -2.9024]],

         [[ 0.7689,    -inf,    -inf,    -inf],
          [-0.7867,  0.8788,    -inf,    -inf],
          [-1.2045, -0.6461,  0.1792,    -inf],
          [ 1.5992,  1.2974,  2.6095,  1.5178]],

         [[-0.9417,    -inf,    -inf,    -inf],
          [ 5.3988, -0.4846,    -inf,    -inf],
          [-2.0497,  1.2294,  3.0581,    -inf],
          [ 2.4859, -1.3673, -1.2563, -0.8478]],

         [[ 2.8521,    -inf,    -inf,    -inf],
          [ 5.5531,  1.4236,    -inf,    -inf],
          [ 0.9316,  0.0852,  1.4256,    -inf],
          [-1.5060,  1.4610,  0.9809, -1.7037]],

         [[-1.4494,    -inf,    -inf,    -inf],
          [ 0.9759,  2.3361,    -inf,    -inf],
          [ 1.1474, -2.6141,  1.8370,    -inf],
          [ 1.1620,  0.0192,  1.5117, -4.8726]],

         [[-0.1563,    -inf,    -inf,    -inf],
          [-0.9255,  2.2866,    -inf,    -inf],
          [ 0.4373,  2.4027, -0.2230,    -inf],
          [ 1.9590, -1.6532, -0.2924,  0.6398]]],


        [[[-2.7538,    -inf,    -inf,    -inf],
          [-6.5033,  0.9874,    -inf,    -inf],
          [ 2.5690, -1.7029, -1.6760,    -inf],
          [ 3.4883, -4.6489,  0.1307,  4.3630]],

         [[-0.3881,    -inf,    -inf,    -inf],
          [ 0.7194,  2.5607,    -inf,    -inf],
          [-1.0136,  2.6440,  2.3192,    -inf],
          [ 1.5569, -2.0869, -1.8644, -1.5261]],

         [[ 5.3692,    -inf,    -inf,    -inf],
          [ 1.1280,  1.1004,    -inf,    -inf],
          [ 3.2275, -2.1077,  2.9624,    -inf],
          [-1.2452,  0.5275,  0.2657, -3.3152]],

         [[-3.2958,    -inf,    -inf,    -inf],
          [ 2.7911, -2.0027,    -inf,    -inf],
          [-2.0515, -0.0987, -5.6008,    -inf],
          [-3.3904, -0.8602, -1.3953,  4.1308]],

         [[ 4.9805,    -inf,    -inf,    -inf],
          [ 1.6964,  2.1793,    -inf,    -inf],
          [ 0.2616,  0.9180,  1.7163,    -inf],
          [-1.5686,  3.4390,  3.6824,  1.4223]],

         [[ 2.4012,    -inf,    -inf,    -inf],
          [ 0.3229, -2.3132,    -inf,    -inf],
          [ 3.3178, -0.8648, -1.3131,    -inf],
          [-1.3808,  1.4659,  3.1666,  4.2573]],

         [[-2.5406,    -inf,    -inf,    -inf],
          [-0.7288,  2.0287,    -inf,    -inf],
          [ 0.6834, -4.3049,  2.0619,    -inf],
          [-0.6421, -2.8358, -0.7856,  2.2456]],

         [[ 1.1350,    -inf,    -inf,    -inf],
          [ 2.4337,  5.9735,    -inf,    -inf],
          [ 2.2667, -2.1464,  0.7315,    -inf],
          [-0.0347,  1.0978,  0.6024,  0.4553]],

         [[ 1.5933,    -inf,    -inf,    -inf],
          [-0.7608, -1.6384,    -inf,    -inf],
          [ 3.3346, -0.2370,  0.2977,    -inf],
          [-2.8944,  2.7261, -2.7417, -5.4433]],

         [[ 1.6374,    -inf,    -inf,    -inf],
          [ 0.0825,  0.3075,    -inf,    -inf],
          [ 3.0984,  1.7380, -1.1743,    -inf],
          [ 0.9610, -3.3473, -0.5385, -1.0962]],

         [[ 2.9763,    -inf,    -inf,    -inf],
          [-6.4965, -0.2624,    -inf,    -inf],
          [-0.8513, -1.5362,  3.4230,    -inf],
          [-0.9650,  0.8047, -0.3094, -6.6811]],

         [[-2.5711,    -inf,    -inf,    -inf],
          [-0.3285,  0.3242,    -inf,    -inf],
          [-3.2146, -0.2453, -0.2311,    -inf],
          [ 0.9251, -1.4006, -2.7559, -0.0601]]]],
       grad_fn=<MaskedFillBackward0>)
context_vec step1:
 tensor([[[[ 1.0308e-01,  3.2378e-01, -7.3201e-01,  ..., -3.8311e-01,
           -4.0873e-02,  5.9249e-02],
          [-7.4617e-01, -1.2702e+00,  7.5960e-01,  ...,  2.7074e-01,
           -3.3868e-01, -4.7294e-01],
          [ 4.0916e-01, -5.2984e-01, -1.8456e-01,  ..., -8.5638e-02,
           -3.6905e-02, -5.9687e-01],
          ...,
          [-9.1300e-01, -1.5857e-01, -1.2576e-01,  ..., -2.0360e-01,
           -1.4905e+00,  1.0140e+00],
          [ 7.4394e-01, -5.0295e-02, -3.1255e-01,  ...,  4.9627e-01,
            4.5020e-01, -2.9625e-01],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
            0.0000e+00,  0.0000e+00]],

         [[ 3.1510e-01,  2.6960e-01, -7.0106e-01,  ..., -4.9951e-01,
            1.5430e-01,  2.4728e-01],
          [-5.8748e-01, -1.0000e+00,  5.9806e-01,  ...,  2.1316e-01,
           -2.6665e-01, -3.7236e-01],
          [ 2.9071e-01, -1.9200e-01, -2.5396e-01,  ...,  2.4672e-01,
           -1.2112e-01,  8.9596e-02],
          ...,
          [-5.0626e-01, -3.4749e-01, -1.1946e-01,  ..., -1.5146e-01,
           -7.3159e-01,  9.5917e-01],
          [ 3.8759e-01, -2.6478e-01,  2.4404e-01,  ..., -1.6130e-02,
            4.6245e-01, -8.3099e-01],
          [ 3.1561e-01, -5.0076e-01, -2.7520e-01,  ...,  1.9185e-01,
           -2.1960e-01,  4.1473e-01]],

         [[ 1.7584e-01,  3.2931e-01, -4.4592e-01,  ..., -3.1976e-01,
            1.8882e-01,  7.0863e-01],
          [-4.0657e-01, -6.6897e-01,  3.8396e-01,  ...,  1.0239e-01,
            1.1862e-02, -3.6032e-02],
          [ 3.2942e-01, -2.8263e-01, -1.1027e-01,  ...,  3.5730e-01,
           -4.4919e-02, -1.9857e-01],
          ...,
          [-4.1656e-01, -2.4800e-01, -2.8088e-02,  ...,  1.3652e-01,
           -1.4108e-01,  2.5323e-01],
          [ 2.6657e-01,  2.4990e-01, -4.8137e-01,  ...,  5.4371e-01,
           -1.4009e-01, -3.3493e-01],
          [-6.5414e-04, -2.8398e-01,  3.9634e-01,  ...,  1.4597e-02,
           -4.9874e-02,  1.6998e-01]],

         [[-1.7430e-01,  1.9721e-01, -2.8936e-01,  ...,  1.0775e-01,
            1.0222e-01,  4.9258e-01],
          [-5.1286e-01, -1.6362e-01,  2.7701e-01,  ...,  6.7072e-02,
            3.2807e-01,  6.4071e-02],
          [ 9.5852e-02, -1.1193e-01, -8.5567e-02,  ...,  3.9528e-01,
           -1.7828e-01, -1.2862e-01],
          ...,
          [-1.4416e-01, -1.4261e-01, -3.3621e-02,  ...,  1.1189e-01,
            5.6741e-02,  1.3186e-01],
          [ 2.4227e-01, -1.2913e-01,  9.0501e-02,  ...,  3.1799e-02,
            2.5431e-01, -4.1624e-01],
          [ 2.4806e-01, -2.7211e-01, -1.0538e-01,  ..., -1.4559e-02,
           -3.5171e-01,  4.9704e-01]]],


        [[[ 1.6549e-01,  6.3096e-01,  1.2783e+00,  ..., -6.7970e-02,
            6.8143e-01,  1.0878e+00],
          [-5.7517e-01, -7.2229e-01, -9.1385e-02,  ...,  1.2228e+00,
           -7.6236e-01,  2.5747e-01],
          [-6.8977e-01, -1.7812e-01, -1.1569e+00,  ..., -3.1793e-01,
           -2.3610e-01,  1.2419e-01],
          ...,
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
            0.0000e+00,  0.0000e+00],
          [ 4.8678e-01, -3.8945e-01,  3.0011e-01,  ..., -4.1835e-01,
           -1.0861e+00,  9.0871e-01],
          [-5.0530e-01,  1.6836e-01, -6.5574e-01,  ...,  1.2180e+00,
           -3.0898e-01, -7.0149e-02]],

         [[-1.8808e-01, -2.9197e-01,  1.6051e-01,  ...,  3.2612e-01,
            1.8502e-01,  8.0030e-01],
          [ 1.0650e-02, -3.9695e-02, -1.5016e-01,  ...,  4.5862e-01,
           -2.4434e-01, -4.5144e-02],
          [-1.9088e-01, -2.1688e-01, -3.8566e-01,  ...,  3.7309e-01,
           -4.0242e-02,  3.6529e-01],
          ...,
          [-6.2215e-01,  1.7597e-02,  1.2262e-01,  ..., -2.3451e-01,
           -3.8867e-01,  4.9419e-01],
          [-8.6781e-02, -4.0760e-01, -6.5673e-01,  ...,  6.0325e-01,
            2.5782e-01,  7.2068e-01],
          [-2.6546e-01,  4.1851e-01, -4.8322e-01,  ...,  2.7461e-01,
           -3.6597e-01,  6.2431e-03]],

         [[ 2.2291e-02,  1.6503e-01,  9.6584e-01,  ..., -1.9618e-02,
            4.9606e-01,  4.4215e-01],
          [-2.1060e-01, -2.7405e-01, -1.5530e-01,  ...,  3.8393e-01,
           -2.8271e-01, -7.3974e-02],
          [-4.4007e-02, -7.3790e-02, -6.9410e-01,  ..., -2.3075e-01,
            7.8274e-02, -1.8248e-02],
          ...,
          [-4.7976e-01, -1.9044e-02,  6.4467e-02,  ..., -2.7597e-01,
           -4.2261e-01,  3.8171e-01],
          [ 4.5690e-02, -2.1281e-01, -1.9471e-01,  ...,  1.5606e-01,
           -7.8225e-02,  4.1143e-01],
          [-6.5089e-01,  7.4963e-01, -5.5277e-01,  ...,  3.6662e-02,
           -8.7155e-02,  3.7202e-01]],

         [[ 5.1717e-02,  1.0078e-01, -1.7172e-02,  ...,  2.1566e-01,
            3.0208e-01, -6.0185e-02],
          [-4.4834e-01, -3.3361e-01, -1.4620e-01,  ...,  6.0678e-01,
           -4.5185e-01,  5.2871e-02],
          [ 3.5955e-02, -1.0563e-01, -3.1762e-01,  ..., -8.3911e-02,
            2.2870e-01,  2.0018e-02],
          ...,
          [-6.4664e-03,  7.4364e-02, -1.1174e-01,  ..., -2.7422e-01,
           -4.1054e-01,  3.3337e-01],
          [ 1.2142e-01, -3.0798e-01, -2.8657e-01,  ...,  2.6634e-01,
           -3.3374e-02,  4.1306e-01],
          [ 1.4635e-01,  5.5364e-01, -1.9152e-01,  ..., -1.5452e-01,
            1.2370e-01,  9.3174e-02]]]], grad_fn=<TransposeBackward0>)
context_vec step2:
 tensor([[[ 0.1031,  0.3238, -0.7320,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.3151,  0.2696, -0.7011,  ...,  0.1918, -0.2196,  0.4147],
         [ 0.1758,  0.3293, -0.4459,  ...,  0.0146, -0.0499,  0.1700],
         [-0.1743,  0.1972, -0.2894,  ..., -0.0146, -0.3517,  0.4970]],

        [[ 0.1655,  0.6310,  1.2783,  ...,  1.2180, -0.3090, -0.0701],
         [-0.1881, -0.2920,  0.1605,  ...,  0.2746, -0.3660,  0.0062],
         [ 0.0223,  0.1650,  0.9658,  ...,  0.0367, -0.0872,  0.3720],
         [ 0.0517,  0.1008, -0.0172,  ..., -0.1545,  0.1237,  0.0932]]],
       grad_fn=<ViewBackward0>)
context_vec step3:
 tensor([[[ 0.0475,  0.0953, -0.2161,  ...,  0.2032, -0.2954,  0.1886],
         [-0.0976, -0.0897, -0.0440,  ..., -0.0691, -0.4102,  0.1129],
         [-0.1272,  0.1372, -0.1857,  ...,  0.0341, -0.2393,  0.1237],
         [-0.0203, -0.0684, -0.1266,  ..., -0.3517, -0.1095,  0.1305]],

        [[-0.5220,  0.2146, -0.0446,  ..., -0.0373, -0.1554, -0.6017],
         [-0.2275,  0.2052,  0.0740,  ..., -0.0152,  0.2024, -0.3164],
         [-0.0618, -0.0686,  0.0686,  ..., -0.2016,  0.0296, -0.4385],
         [ 0.1656, -0.1838, -0.0162,  ..., -0.1162, -0.0292,  0.0172]]],
       grad_fn=<ViewBackward0>)
Transformer: Input Shape:  torch.Size([2, 4, 768]) 

Transformer: Output Shape:  torch.Size([2, 4, 768]) 

Transformer Output: 
 tensor([[[ 0.1648,  0.4002, -0.0749,  ...,  1.2646,  0.3324,  0.7243],
         [ 0.0293,  0.0498,  0.2529,  ...,  0.4698,  0.1281,  0.9749],
         [ 0.5532,  0.5788, -0.0310,  ...,  1.1544,  0.3947,  0.7600],
         [ 0.1631,  0.7128,  0.7271,  ...,  0.3312,  0.5730,  0.9258]],

        [[ 0.1787,  1.1682,  0.5810,  ...,  0.1828,  0.0073, -0.5603],
         [-0.2920,  0.6318,  0.2002,  ...,  0.3218,  0.4670, -0.0383],
         [ 0.9275,  0.4203,  0.3183,  ...,  0.3771,  0.7190, -0.1205],
         [ 0.6035,  0.5767,  0.3411,  ...,  1.3798,  1.2683,  0.3916]]],
       grad_fn=<AddBackward0>)
