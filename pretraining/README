Thus far I have implemented the data sampling and attention mechanism and coded the LLM architecture:

1. tokenizers
2. attention
3. llm-infra

Now implement a training function and pretrain the LLM. Walk through and code all concepts.
(training, or "pre-training" of a model w.r.t post optimizations)

4. pretraining (this)

Follow up with basic model evaluation techniques to measure the quality of the generated text (which is a requirement 
for optimizing the LLM during the training process). 

Finally load pretrained weights (instead of spending time on training or showing it here how its done)
This preps my LLM for fine tuning next.

Note that with llm-infra the entire flow has already been coded for the LLM. The strategy is to now
hone in on how the weights (be it in the attention module (q,k,v weights) or in the feed forward network or in the 
layer norm layer or overall in the transformer block, are actually obtained)

3 main steps in the pre-training process:

1. training loop (core)
2. model evaluation (feedback loop)
3. load pre-trained weights (and make this scalable)

an alternative to 3 would be to implement training myself with appdx-D and Gutenberg
(see template-gutenberg.py)

Order of perusal:
textgenerate.py
eval-textgenerate.py
loss-training-validation.py






