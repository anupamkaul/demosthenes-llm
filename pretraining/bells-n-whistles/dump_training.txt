device:  cpu
enter..device override for my local ubuntu:  cpu
model not found on disk. monitor as a one time thing, error out if repeats
Characters: 425885
Tokens: 90514
90% of the split is from index  383296

OS:  Darwin  batch size:  8  enter..
GPTDatasetV1.py generated token IDs !
GPTDatasetV1.py chunking tokens for max_length =  256  stride =  256
GPTDatasetV1.py tokenization done!
GPTDatasetV1.py generated token IDs !
GPTDatasetV1.py chunking tokens for max_length =  256  stride =  256
GPTDatasetV1.py tokenization done!
Train loader:
torch.Size([8, 256]) torch.Size([8, 256])
torch.Size([8, 256]) torch.Size([8, 256])
torch.Size([8, 256]) torch.Size([8, 256])
torch.Size([8, 256]) torch.Size([8, 256])
torch.Size([8, 256]) torch.Size([8, 256])
torch.Size([8, 256]) torch.Size([8, 256])
torch.Size([8, 256]) torch.Size([8, 256])
torch.Size([8, 256]) torch.Size([8, 256])
torch.Size([8, 256]) torch.Size([8, 256])
torch.Size([8, 256]) torch.Size([8, 256])
torch.Size([8, 256]) torch.Size([8, 256])
torch.Size([8, 256]) torch.Size([8, 256])
torch.Size([8, 256]) torch.Size([8, 256])
torch.Size([8, 256]) torch.Size([8, 256])
torch.Size([8, 256]) torch.Size([8, 256])
torch.Size([8, 256]) torch.Size([8, 256])
torch.Size([8, 256]) torch.Size([8, 256])
torch.Size([8, 256]) torch.Size([8, 256])
torch.Size([8, 256]) torch.Size([8, 256])
torch.Size([8, 256]) torch.Size([8, 256])
torch.Size([8, 256]) torch.Size([8, 256])
torch.Size([8, 256]) torch.Size([8, 256])
torch.Size([8, 256]) torch.Size([8, 256])
torch.Size([8, 256]) torch.Size([8, 256])
torch.Size([8, 256]) torch.Size([8, 256])
torch.Size([8, 256]) torch.Size([8, 256])
torch.Size([8, 256]) torch.Size([8, 256])
torch.Size([8, 256]) torch.Size([8, 256])
torch.Size([8, 256]) torch.Size([8, 256])
torch.Size([8, 256]) torch.Size([8, 256])
torch.Size([8, 256]) torch.Size([8, 256])
torch.Size([8, 256]) torch.Size([8, 256])
torch.Size([8, 256]) torch.Size([8, 256])
torch.Size([8, 256]) torch.Size([8, 256])
torch.Size([8, 256]) torch.Size([8, 256])
torch.Size([8, 256]) torch.Size([8, 256])
torch.Size([8, 256]) torch.Size([8, 256])
torch.Size([8, 256]) torch.Size([8, 256])
torch.Size([8, 256]) torch.Size([8, 256])

Validation loader:
torch.Size([8, 256]) torch.Size([8, 256])
torch.Size([8, 256]) torch.Size([8, 256])
torch.Size([8, 256]) torch.Size([8, 256])
torch.Size([8, 256]) torch.Size([8, 256])
torch.Size([2, 256]) torch.Size([2, 256])
GPTModel(
  (tok_emb): Embedding(50257, 768)
  (pos_emb): Embedding(256, 768)
  (drop_emb): Dropout(p=0.1, inplace=False)
  (trf_blocks): Sequential(
    (0): TransformerBlock(
      (att): MultiHeadAttention(
        (W_query): Linear(in_features=768, out_features=768, bias=False)
        (W_key): Linear(in_features=768, out_features=768, bias=False)
        (W_value): Linear(in_features=768, out_features=768, bias=False)
        (out_proj): Linear(in_features=768, out_features=768, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (ff): FeedForward(
        (layers): Sequential(
          (0): Linear(in_features=768, out_features=3072, bias=True)
          (1): GELU()
          (2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
      (norm1): LayerNorm()
      (norm2): LayerNorm()
      (drop_shortcut): Dropout(p=0.1, inplace=False)
    )
    (1): TransformerBlock(
      (att): MultiHeadAttention(
        (W_query): Linear(in_features=768, out_features=768, bias=False)
        (W_key): Linear(in_features=768, out_features=768, bias=False)
        (W_value): Linear(in_features=768, out_features=768, bias=False)
        (out_proj): Linear(in_features=768, out_features=768, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (ff): FeedForward(
        (layers): Sequential(
          (0): Linear(in_features=768, out_features=3072, bias=True)
          (1): GELU()
          (2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
      (norm1): LayerNorm()
      (norm2): LayerNorm()
      (drop_shortcut): Dropout(p=0.1, inplace=False)
    )
    (2): TransformerBlock(
      (att): MultiHeadAttention(
        (W_query): Linear(in_features=768, out_features=768, bias=False)
        (W_key): Linear(in_features=768, out_features=768, bias=False)
        (W_value): Linear(in_features=768, out_features=768, bias=False)
        (out_proj): Linear(in_features=768, out_features=768, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (ff): FeedForward(
        (layers): Sequential(
          (0): Linear(in_features=768, out_features=3072, bias=True)
          (1): GELU()
          (2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
      (norm1): LayerNorm()
      (norm2): LayerNorm()
      (drop_shortcut): Dropout(p=0.1, inplace=False)
    )
    (3): TransformerBlock(
      (att): MultiHeadAttention(
        (W_query): Linear(in_features=768, out_features=768, bias=False)
        (W_key): Linear(in_features=768, out_features=768, bias=False)
        (W_value): Linear(in_features=768, out_features=768, bias=False)
        (out_proj): Linear(in_features=768, out_features=768, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (ff): FeedForward(
        (layers): Sequential(
          (0): Linear(in_features=768, out_features=3072, bias=True)
          (1): GELU()
          (2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
      (norm1): LayerNorm()
      (norm2): LayerNorm()
      (drop_shortcut): Dropout(p=0.1, inplace=False)
    )
    (4): TransformerBlock(
      (att): MultiHeadAttention(
        (W_query): Linear(in_features=768, out_features=768, bias=False)
        (W_key): Linear(in_features=768, out_features=768, bias=False)
        (W_value): Linear(in_features=768, out_features=768, bias=False)
        (out_proj): Linear(in_features=768, out_features=768, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (ff): FeedForward(
        (layers): Sequential(
          (0): Linear(in_features=768, out_features=3072, bias=True)
          (1): GELU()
          (2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
      (norm1): LayerNorm()
      (norm2): LayerNorm()
      (drop_shortcut): Dropout(p=0.1, inplace=False)
    )
    (5): TransformerBlock(
      (att): MultiHeadAttention(
        (W_query): Linear(in_features=768, out_features=768, bias=False)
        (W_key): Linear(in_features=768, out_features=768, bias=False)
        (W_value): Linear(in_features=768, out_features=768, bias=False)
        (out_proj): Linear(in_features=768, out_features=768, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (ff): FeedForward(
        (layers): Sequential(
          (0): Linear(in_features=768, out_features=3072, bias=True)
          (1): GELU()
          (2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
      (norm1): LayerNorm()
      (norm2): LayerNorm()
      (drop_shortcut): Dropout(p=0.1, inplace=False)
    )
    (6): TransformerBlock(
      (att): MultiHeadAttention(
        (W_query): Linear(in_features=768, out_features=768, bias=False)
        (W_key): Linear(in_features=768, out_features=768, bias=False)
        (W_value): Linear(in_features=768, out_features=768, bias=False)
        (out_proj): Linear(in_features=768, out_features=768, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (ff): FeedForward(
        (layers): Sequential(
          (0): Linear(in_features=768, out_features=3072, bias=True)
          (1): GELU()
          (2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
      (norm1): LayerNorm()
      (norm2): LayerNorm()
      (drop_shortcut): Dropout(p=0.1, inplace=False)
    )
    (7): TransformerBlock(
      (att): MultiHeadAttention(
        (W_query): Linear(in_features=768, out_features=768, bias=False)
        (W_key): Linear(in_features=768, out_features=768, bias=False)
        (W_value): Linear(in_features=768, out_features=768, bias=False)
        (out_proj): Linear(in_features=768, out_features=768, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (ff): FeedForward(
        (layers): Sequential(
          (0): Linear(in_features=768, out_features=3072, bias=True)
          (1): GELU()
          (2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
      (norm1): LayerNorm()
      (norm2): LayerNorm()
      (drop_shortcut): Dropout(p=0.1, inplace=False)
    )
    (8): TransformerBlock(
      (att): MultiHeadAttention(
        (W_query): Linear(in_features=768, out_features=768, bias=False)
        (W_key): Linear(in_features=768, out_features=768, bias=False)
        (W_value): Linear(in_features=768, out_features=768, bias=False)
        (out_proj): Linear(in_features=768, out_features=768, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (ff): FeedForward(
        (layers): Sequential(
          (0): Linear(in_features=768, out_features=3072, bias=True)
          (1): GELU()
          (2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
      (norm1): LayerNorm()
      (norm2): LayerNorm()
      (drop_shortcut): Dropout(p=0.1, inplace=False)
    )
    (9): TransformerBlock(
      (att): MultiHeadAttention(
        (W_query): Linear(in_features=768, out_features=768, bias=False)
        (W_key): Linear(in_features=768, out_features=768, bias=False)
        (W_value): Linear(in_features=768, out_features=768, bias=False)
        (out_proj): Linear(in_features=768, out_features=768, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (ff): FeedForward(
        (layers): Sequential(
          (0): Linear(in_features=768, out_features=3072, bias=True)
          (1): GELU()
          (2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
      (norm1): LayerNorm()
      (norm2): LayerNorm()
      (drop_shortcut): Dropout(p=0.1, inplace=False)
    )
    (10): TransformerBlock(
      (att): MultiHeadAttention(
        (W_query): Linear(in_features=768, out_features=768, bias=False)
        (W_key): Linear(in_features=768, out_features=768, bias=False)
        (W_value): Linear(in_features=768, out_features=768, bias=False)
        (out_proj): Linear(in_features=768, out_features=768, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (ff): FeedForward(
        (layers): Sequential(
          (0): Linear(in_features=768, out_features=3072, bias=True)
          (1): GELU()
          (2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
      (norm1): LayerNorm()
      (norm2): LayerNorm()
      (drop_shortcut): Dropout(p=0.1, inplace=False)
    )
    (11): TransformerBlock(
      (att): MultiHeadAttention(
        (W_query): Linear(in_features=768, out_features=768, bias=False)
        (W_key): Linear(in_features=768, out_features=768, bias=False)
        (W_value): Linear(in_features=768, out_features=768, bias=False)
        (out_proj): Linear(in_features=768, out_features=768, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (ff): FeedForward(
        (layers): Sequential(
          (0): Linear(in_features=768, out_features=3072, bias=True)
          (1): GELU()
          (2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
      (norm1): LayerNorm()
      (norm2): LayerNorm()
      (drop_shortcut): Dropout(p=0.1, inplace=False)
    )
  )
  (final_norm): LayerNorm()
  (out_head): Linear(in_features=768, out_features=50257, bias=False)
)
device:  cpu
calc_loss_loader..
num_batches:  39 len of data_loader:  39
0 of 391 of 392 of 393 of 394 of 395 of 396 of 397 of 398 of 399 of 3910 of 3911 of 3912 of 3913 of 3914 of 3915 of 3916 of 3917 of 3918 of 3919 of 3920 of 3921 of 3922 of 3923 of 3924 of 3925 of 3926 of 3927 of 3928 of 3929 of 3930 of 3931 of 3932 of 3933 of 3934 of 3935 of 3936 of 3937 of 3938 of 39finish calc_loss_loader..
calc_loss_loader..
num_batches:  5 len of data_loader:  5
0 of 51 of 52 of 53 of 54 of 5finish calc_loss_loader..
Training loss:  10.979951247190817
Validation loss:  10.9568115234375
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  0  tokens seen:  2048
calc_loss_loader..
num_batches:  1 len of data_loader:  39
0 of 391 of 39finish calc_loss_loader..
calc_loss_loader..
num_batches:  1 len of data_loader:  5
0 of 51 of 5finish calc_loss_loader..
Epoch 1 (Step 000000): Train loss 10.943, Val loss 10.900
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  1  tokens seen:  4096
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  2  tokens seen:  6144
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  3  tokens seen:  8192
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  4  tokens seen:  10240
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  5  tokens seen:  12288
calc_loss_loader..
num_batches:  1 len of data_loader:  39
0 of 391 of 39finish calc_loss_loader..
calc_loss_loader..
num_batches:  1 len of data_loader:  5
0 of 51 of 5finish calc_loss_loader..
Epoch 1 (Step 000005): Train loss 8.985, Val loss 9.189
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  6  tokens seen:  14336
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  7  tokens seen:  16384
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  8  tokens seen:  18432
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  9  tokens seen:  20480
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  10  tokens seen:  22528
calc_loss_loader..
num_batches:  1 len of data_loader:  39
0 of 391 of 39finish calc_loss_loader..
calc_loss_loader..
num_batches:  1 len of data_loader:  5
0 of 51 of 5finish calc_loss_loader..
Epoch 1 (Step 000010): Train loss 7.914, Val loss 8.081
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  11  tokens seen:  24576
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  12  tokens seen:  26624
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  13  tokens seen:  28672
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  14  tokens seen:  30720
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  15  tokens seen:  32768
calc_loss_loader..
num_batches:  1 len of data_loader:  39
0 of 391 of 39finish calc_loss_loader..
calc_loss_loader..
num_batches:  1 len of data_loader:  5
0 of 51 of 5finish calc_loss_loader..
Epoch 1 (Step 000015): Train loss 7.663, Val loss 8.114
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  16  tokens seen:  34816
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  17  tokens seen:  36864
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  18  tokens seen:  38912
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  19  tokens seen:  40960
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  20  tokens seen:  43008
calc_loss_loader..
num_batches:  1 len of data_loader:  39
0 of 391 of 39finish calc_loss_loader..
calc_loss_loader..
num_batches:  1 len of data_loader:  5
0 of 51 of 5finish calc_loss_loader..
Epoch 1 (Step 000020): Train loss 7.944, Val loss 8.231
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  21  tokens seen:  45056
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  22  tokens seen:  47104
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  23  tokens seen:  49152
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  24  tokens seen:  51200
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  25  tokens seen:  53248
calc_loss_loader..
num_batches:  1 len of data_loader:  39
0 of 391 of 39finish calc_loss_loader..
calc_loss_loader..
num_batches:  1 len of data_loader:  5
0 of 51 of 5finish calc_loss_loader..
Epoch 1 (Step 000025): Train loss 7.328, Val loss 7.980
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  26  tokens seen:  55296
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  27  tokens seen:  57344
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  28  tokens seen:  59392
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  29  tokens seen:  61440
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  30  tokens seen:  63488
calc_loss_loader..
num_batches:  1 len of data_loader:  39
0 of 391 of 39finish calc_loss_loader..
calc_loss_loader..
num_batches:  1 len of data_loader:  5
0 of 51 of 5finish calc_loss_loader..
Epoch 1 (Step 000030): Train loss 7.087, Val loss 7.944
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  31  tokens seen:  65536
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  32  tokens seen:  67584
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  33  tokens seen:  69632
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  34  tokens seen:  71680
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  35  tokens seen:  73728
calc_loss_loader..
num_batches:  1 len of data_loader:  39
0 of 391 of 39finish calc_loss_loader..
calc_loss_loader..
num_batches:  1 len of data_loader:  5
0 of 51 of 5finish calc_loss_loader..
Epoch 1 (Step 000035): Train loss 7.108, Val loss 7.863
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  36  tokens seen:  75776
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  37  tokens seen:  77824
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  38  tokens seen:  79872

out of inner input_batch loop..
generate and print sample..

Every effort moves you, the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  39  tokens seen:  81920
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  40  tokens seen:  83968
calc_loss_loader..
num_batches:  1 len of data_loader:  39
0 of 391 of 39finish calc_loss_loader..
calc_loss_loader..
num_batches:  1 len of data_loader:  5
0 of 51 of 5finish calc_loss_loader..
Epoch 2 (Step 000040): Train loss 7.149, Val loss 7.787
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  41  tokens seen:  86016
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  42  tokens seen:  88064
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  43  tokens seen:  90112
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  44  tokens seen:  92160
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  45  tokens seen:  94208
calc_loss_loader..
num_batches:  1 len of data_loader:  39
0 of 391 of 39finish calc_loss_loader..
calc_loss_loader..
num_batches:  1 len of data_loader:  5
0 of 51 of 5finish calc_loss_loader..
Epoch 2 (Step 000045): Train loss 6.978, Val loss 7.696
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  46  tokens seen:  96256
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  47  tokens seen:  98304
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  48  tokens seen:  100352
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  49  tokens seen:  102400
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  50  tokens seen:  104448
calc_loss_loader..
num_batches:  1 len of data_loader:  39
0 of 391 of 39finish calc_loss_loader..
calc_loss_loader..
num_batches:  1 len of data_loader:  5
0 of 51 of 5finish calc_loss_loader..
Epoch 2 (Step 000050): Train loss 6.885, Val loss 7.638
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  51  tokens seen:  106496
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  52  tokens seen:  108544
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  53  tokens seen:  110592
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  54  tokens seen:  112640
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  55  tokens seen:  114688
calc_loss_loader..
num_batches:  1 len of data_loader:  39
0 of 391 of 39finish calc_loss_loader..
calc_loss_loader..
num_batches:  1 len of data_loader:  5
0 of 51 of 5finish calc_loss_loader..
Epoch 2 (Step 000055): Train loss 6.878, Val loss 7.622
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  56  tokens seen:  116736
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  57  tokens seen:  118784
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  58  tokens seen:  120832
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  59  tokens seen:  122880
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  60  tokens seen:  124928
calc_loss_loader..
num_batches:  1 len of data_loader:  39
0 of 391 of 39finish calc_loss_loader..
calc_loss_loader..
num_batches:  1 len of data_loader:  5
0 of 51 of 5finish calc_loss_loader..
Epoch 2 (Step 000060): Train loss 6.931, Val loss 7.598
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  61  tokens seen:  126976
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  62  tokens seen:  129024
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  63  tokens seen:  131072
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  64  tokens seen:  133120
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  65  tokens seen:  135168
calc_loss_loader..
num_batches:  1 len of data_loader:  39
0 of 391 of 39finish calc_loss_loader..
calc_loss_loader..
num_batches:  1 len of data_loader:  5
0 of 51 of 5finish calc_loss_loader..
Epoch 2 (Step 000065): Train loss 6.999, Val loss 7.602
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  66  tokens seen:  137216
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  67  tokens seen:  139264
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  68  tokens seen:  141312
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  69  tokens seen:  143360
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  70  tokens seen:  145408
calc_loss_loader..
num_batches:  1 len of data_loader:  39
0 of 391 of 39finish calc_loss_loader..
calc_loss_loader..
num_batches:  1 len of data_loader:  5
0 of 51 of 5finish calc_loss_loader..
Epoch 2 (Step 000070): Train loss 6.838, Val loss 7.538
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  71  tokens seen:  147456
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  72  tokens seen:  149504
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  73  tokens seen:  151552
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  74  tokens seen:  153600
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  75  tokens seen:  155648
calc_loss_loader..
num_batches:  1 len of data_loader:  39
0 of 391 of 39finish calc_loss_loader..
calc_loss_loader..
num_batches:  1 len of data_loader:  5
0 of 51 of 5finish calc_loss_loader..
Epoch 2 (Step 000075): Train loss 6.876, Val loss 7.542
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  76  tokens seen:  157696
debug: len input batch:  8  len target batch:  8  len train loader :  39
debug: global_step :  77  tokens seen:  159744

out of inner input_batch loop..
generate and print sample..

Every effort moves you, and the state, and the state, and the state, and the state, and the state, and the state, and the state, and the state, and the state, and the state, and the state the state, and the state
model saved

tokens seen:  [2048, 12288, 22528, 32768, 43008, 53248, 63488, 73728, 83968, 94208, 104448, 114688, 124928, 135168, 145408, 155648]
