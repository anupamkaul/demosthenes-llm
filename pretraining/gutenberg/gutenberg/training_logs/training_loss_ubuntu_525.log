the bottom parts ..

global step:  522  tokens seen:  1069056
523  input batch:  tensor([[  198,    34,   274,  ...,   359,  4548, 28141],
        [ 3313, 12685,   494,  ...,  8704,   555, 17717]]) 
target batch :  tensor([[   34,   274,  3297,  ...,  4548, 28141, 17809],
        [12685,   494,  2821,  ...,   555, 17717,   260]])
optimizer setting
optimizer set
loss calculating
loss calculated
backprop start
backprop end
optimizer step start
optimizer step end
we have tokens_seen
global step:  523  tokens seen:  1071104
524  input batch:  tensor([[11691,   345,   714,  ...,  1913,  3392, 30692],
        [  504, 10287,   474,  ...,   198,  1169,  3944]]) 
target batch :  tensor([[  345,   714,   407,  ...,  3392, 30692,   992],
        [10287,   474,  1798,  ...,  1169,  3944,    85]])
optimizer setting
optimizer set
loss calculating
loss calculated
backprop start
backprop end
optimizer step start
optimizer step end
we have tokens_seen
global step:  524  tokens seen:  1073152
525  input batch:  tensor([[ 11, 438,  40,  ...,  11, 198, 259],
        [220, 220, 220,  ..., 220, 220, 220]]) 
target batch :  tensor([[438,  40, 198,  ..., 198, 259, 543],
        [220, 220, 220,  ..., 220, 220, 220]])
optimizer setting
optimizer set
loss calculating
loss calculated
backprop start
backprop end
optimizer step start
optimizer step end
we have tokens_seen
global step:  525  tokens seen:  1075200
evaluating model, noting train + validation loss (interim)
Ep 1 (Step 525): Train loss 7.364, Val loss 6.720

generate and print sample..
Every effort moves you                                                  
526  input batch:  tensor([[  284,   787,   465,  ...,   609,   446,    11],
        [ 4512,    11,   198,  ...,   287, 12921,   286]]) 
target batch :  tensor([[  787,   465,   198,  ...,   446,    11,   198],
        [   11,   198, 24571,  ..., 12921,   286,   262]])
optimizer setting
optimizer set
loss calculating
^CSaved model_checkpoints/model_and_optmzr_pg_525_interrupted.pth and model_checkpoints/model_and_optmzr_pg_final.pth
Training state saved for epoch 0 file index 1 batch_counter  526 tokens 1075200 global_step 525
Saved training state
tokens_seen[] =  [215040, 225280, 235520, 245760, 256000, 266240, 276480, 286720, 296960, 307200, 317440, 327680, 337920, 348160, 358400, 368640, 378880, 389120, 399360, 409600, 419840, 430080, 440320, 450560, 460800, 471040, 481280, 491520, 501760, 512000, 522240, 532480, 542720, 552960, 563200, 573440, 583680, 593920, 604160, 614400, 624640, 634880, 645120, 655360, 665600, 675840, 686080, 696320, 706560, 716800, 727040, 737280, 747520, 757760, 768000, 778240, 788480, 798720, 808960, 819200, 829440, 839680, 849920, 860160, 870400, 880640, 890880, 901120, 911360, 921600, 931840, 942080, 952320, 962560, 972800, 983040, 993280, 1003520, 1013760, 1024000, 1034240, 1044480, 1054720, 1064960, 1075200]
train_losses[] =  [7.536464214324951, 7.348625183105469, 7.819932460784912, 7.1900553703308105, 7.325741291046143, 5.588564395904541, 7.461556911468506, 7.246492862701416, 7.281182765960693, 6.716677188873291, 6.906765460968018, 7.28606653213501, 7.500924110412598, 6.914889335632324, 7.050201416015625, 6.729560375213623, 6.970057010650635, 7.395885944366455, 7.1797356605529785, 4.645638465881348, 6.897027969360352, 4.854908466339111, 6.39832067489624, 6.532585620880127, 6.411539554595947, 6.211590766906738, 7.855869293212891, 6.417499542236328, 7.3436455726623535, 6.422206401824951, 6.765359878540039, 6.643083095550537, 4.534334182739258, 6.869826793670654, 8.109444618225098, 7.053272724151611, 6.75388765335083, 6.82327127456665, 6.432815074920654, 7.3484063148498535, 6.574554920196533, 6.688645362854004, 6.8011040687561035, 6.323726654052734, 6.991821765899658, 6.584654808044434, 6.073414325714111, 6.652502059936523, 4.023151397705078, 4.432931900024414, 6.549890518188477, 6.199187755584717, 6.305058002471924, 6.372184753417969, 6.571787357330322, 6.535295009613037, 6.369748115539551, 4.710291385650635, 6.493282318115234, 6.268102645874023, 6.196465492248535, 6.731125354766846, 6.399028301239014, 6.211669445037842, 4.498452663421631, 6.527243137359619, 6.6406941413879395, 6.248566627502441, 6.608564376831055, 6.221710681915283, 6.3981194496154785, 6.120729923248291, 6.721179008483887, 6.491308689117432, 6.170359134674072, 6.368590354919434, 6.629378318786621, 6.886383056640625, 6.104463577270508, 6.309625625610352, 6.413571834564209, 6.456500053405762, 6.438838005065918, 6.45905065536499, 7.364251136779785]
val_losses[] =  [7.3613481521606445, 7.568441390991211, 7.388110637664795, 7.322494029998779, 7.330507755279541, 7.339406490325928, 7.315905570983887, 7.261422157287598, 7.177158355712891, 7.279703617095947, 7.281754970550537, 7.291499614715576, 7.148197174072266, 7.2479634284973145, 7.250316143035889, 7.173598766326904, 7.139991283416748, 7.1202216148376465, 7.226569175720215, 7.1044921875, 7.153415203094482, 7.110113143920898, 7.033343315124512, 7.055625915527344, 7.026674270629883, 6.986761569976807, 7.005976676940918, 7.102512836456299, 6.96757698059082, 6.989046573638916, 6.986068248748779, 6.998543739318848, 6.948913097381592, 6.913022518157959, 6.907914638519287, 6.980169773101807, 6.945418834686279, 7.001864910125732, 7.029641628265381, 7.004465579986572, 6.985051155090332, 6.948309421539307, 6.931293487548828, 6.968591690063477, 6.899307727813721, 6.875844478607178, 6.879281520843506, 6.932907581329346, 6.871581554412842, 6.8701372146606445, 7.03659725189209, 6.938838481903076, 6.938388347625732, 6.9379658699035645, 6.94398832321167, 6.869055271148682, 6.9014201164245605, 6.908871650695801, 6.876943588256836, 6.842066764831543, 6.835020542144775, 6.838749408721924, 6.82827615737915, 6.807494163513184, 6.83292818069458, 6.816612243652344, 6.799358367919922, 6.791756629943848, 6.77095365524292, 6.764732837677002, 6.758270263671875, 6.767977237701416, 6.741132736206055, 6.757043361663818, 6.731886863708496, 6.74368953704834, 6.746682643890381, 6.764442443847656, 6.7443671226501465, 6.750280857086182, 6.736708164215088, 6.7092976570129395, 6.69087553024292, 6.672322750091553, 6.720440864562988]
Maximum GPU memory allocated: 0.00 GB

