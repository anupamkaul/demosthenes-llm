'''
Lets now prep up the infra for writing up the loss function
and dividing the data set into training and validation sizes

previously in eval.. we looked at cross-entropy as the loss
function (negative average log probability difference between target and current iteration)

We apply the loss calculation to the entire dataset

The dataset size:
1. Start with "The Verdict"
2. Explore Project Gutenberg
3. Scale with Llama like LLMs (7B parameter), and go to 175B, 1T etc
'''






